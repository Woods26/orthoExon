{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gffutils\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "import json\n",
    "from pyfaidx import Fasta\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# globals\n",
    "template_species_list = [\"Bcur\", \"Bdor\", \"Bole\", \"Ccap\"]\n",
    "transvestigated_species_set = {'Bcor', 'Blat', 'Bzon', 'Afra', 'Bmin', 'Bjar', 'Aobl'}\n",
    "gff_path = \"./input/gff/\"\n",
    "fasta_path = \"./input/fasta/\"\n",
    "groups_fn = \"./input/groups_filtered_6181genes.txt\"\n",
    "output_path = \"./output/\"\n",
    "intermediate_path = \"./intermediate/\"\n",
    "aligned_fasta_path = \"./input/aligned_13spp_fasta/\"\n",
    "\n",
    "# gap filter parameters\n",
    "max_gap_percent = 0\n",
    "max_gap_length = 0\n",
    "# cds length filter parameters\n",
    "min_cds_length = 400\n",
    "max_cds_length = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create handles for all .db files in intermediate directory\n",
    "gff_fn = {name.split('.gff.db')[0]: intermediate_path + name for name in os.listdir(intermediate_path) if \".gff.db\" in name}\n",
    "gff = {key: gffutils.FeatureDB(value) for key, value in gff_fn.items()}\n",
    "\n",
    "# create handles for all .fasta files in fasta directory\n",
    "fasta_fn = {name.split('.nt.fasta')[0]: fasta_path + name for name in os.listdir(fasta_path) if\n",
    "         ((\".nt.fasta\" in name) and (\".nt.fasta.fai\" not in name))}\n",
    "fasta = {key: Fasta(value) for key, value in fasta_fn.items()}\n",
    "        \n",
    "# import ortholog groups\n",
    "with open(intermediate_path + \"groups.json\", 'r') as f:\n",
    "    parent_groups = json.load(f)\n",
    "\n",
    "# create handles for all .fasta files in aligned_13spp_fasta directory\n",
    "aligned_fasta_fn = {name.split('.13spp')[0]: aligned_fasta_path + name for name in os.listdir(aligned_fasta_path) if\n",
    "         ((\".fasta.aln\" in name) and (\".fasta.aln.fai\" not in name))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define functions to parse coordinates of cds's from concatinated aligned fasta w/ n's and -'s\n",
    "nnn = 50\n",
    "def findBreakpoints(seq):\n",
    "    breakpoints = []\n",
    "    loc = 0\n",
    "    regex = re.compile(r\"n+[-+n+]*\")\n",
    "    while(True):\n",
    "        #loc = seq.find(nnn, loc)\n",
    "        match = regex.search(seq, loc)\n",
    "        if not match:\n",
    "            break\n",
    "        if len(match.group().replace('-', '')) >= nnn:\n",
    "            breakpoints.append(match.span())\n",
    "        loc = match.end()\n",
    "    return(breakpoints)\n",
    "\n",
    "def findExonCoords(seq):\n",
    "    breakpoints = findBreakpoints(seq)\n",
    "    length = len(seq)\n",
    "\n",
    "    if len(breakpoints) == 0:\n",
    "        return([(0, length)])\n",
    "\n",
    "    if len(breakpoints) == 1:\n",
    "        bp = breakpoints[0]\n",
    "        return([(0, bp[0]), (bp[1], length)])\n",
    "\n",
    "    elif len(breakpoints) > 0:\n",
    "        exonCoords = []\n",
    "        exonCoords.append((0, breakpoints[0][0])) # first exon\n",
    "\n",
    "        for i in range(len(breakpoints) + 1)[1:-1]: # all intermediate exons\n",
    "            ex_start = breakpoints[i-1][1]\n",
    "            ex_end = breakpoints[i][0]\n",
    "            exonCoords.append((ex_start, ex_end))\n",
    "\n",
    "        exonCoords.append((breakpoints[-1][1], length)) # last exon\n",
    "        return(exonCoords)\n",
    "    \n",
    "def gapPercent(seq):\n",
    "    seq = str(seq)\n",
    "    gappedLen = len(seq)\n",
    "    gapCount = seq.count('-')\n",
    "    return( (100.0*gapCount)/gappedLen )\n",
    "\n",
    "def longestGap(seq):\n",
    "    seq = str(seq)\n",
    "    gap_regex = re.compile(r\"-+\")\n",
    "    gap_list = gap_regex.findall(seq)\n",
    "    if gap_list:\n",
    "        return(sorted([len(gap) for gap in gap_list], reverse=True)[0])\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read and parse fasta files for each species\n",
    "aligned_fasta = {}\n",
    "for ortho in aligned_fasta_fn.keys():\n",
    "    aligned_fasta[ortho] = {seq_record.id : seq_record \n",
    "                                      for seq_record in SeqIO.parse(aligned_fasta_fn[ortho],\n",
    "                                                                    \"fasta\", alphabet=IUPAC.ambiguous_dna)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parse coords from template species in aligned fasta's and trash entries w/ all gaps\n",
    "coords = {} # coords[ortho][sp] = [coord, ]\n",
    "for ortho in aligned_fasta:\n",
    "    coords[ortho] = {}\n",
    "    for sp in template_species_list:\n",
    "        seq = str(aligned_fasta[ortho][sp].seq)\n",
    "        temp_coords = findExonCoords(str(aligned_fasta[ortho][sp].seq))\n",
    "        for start,end in temp_coords:\n",
    "            cds = seq[start:end]\n",
    "            if len(cds) != cds.count('-'):\n",
    "                if sp not in coords[ortho]:\n",
    "                    coords[ortho][sp] = (start,end)\n",
    "                elif type(coords[ortho][sp]) is list:\n",
    "                    coords[ortho][sp].append((start,end))\n",
    "                else:\n",
    "                    temp = coords[ortho][sp]\n",
    "                    coords[ortho][sp] = [temp, (start,end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sanity check for multiple non gap template cds's per ortho,sp\n",
    "for ortho in coords:\n",
    "    for sp in coords[ortho]:\n",
    "        if type(coords[ortho][sp]) is list:\n",
    "            print(\"error, multiple non-gap template cds's for {},{}: {}\".format(ortho, sp, coords[ortho][sp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter aligned exons\n",
    "ortho_coords = {}\n",
    "for ortho in coords:\n",
    "    ortho_coords[ortho] = {}\n",
    "    for sp in coords[ortho]:\n",
    "        coord = coords[ortho][sp]\n",
    "\n",
    "        # filter for length\n",
    "        start, end = coord\n",
    "        length = end - start\n",
    "        if not min_cds_length <= length <= max_cds_length:\n",
    "            continue\n",
    "\n",
    "        # filter for gap percent\n",
    "        seq = str(aligned_fasta[ortho][sp].seq[start:end])\n",
    "        if gapPercent(seq) > max_gap_percent:\n",
    "            continue\n",
    "\n",
    "        # filter for gap length\n",
    "        if longestGap(seq) > max_gap_length:\n",
    "            continue\n",
    "\n",
    "        # prep to filter for species membership of ortho\n",
    "        if coord not in ortho_coords[ortho].keys():\n",
    "            ortho_coords[ortho][coord] = set()\n",
    "        ortho_coords[ortho][coord].add(sp)\n",
    "\n",
    "# set of coords per ortho which were represented in all species\n",
    "universal_ortho_coords = {}\n",
    "for ortho in ortho_coords:\n",
    "    for coord in ortho_coords[ortho]:\n",
    "        sp_set = ortho_coords[ortho][coord]\n",
    "        if len(sp_set) == len(template_species_list):\n",
    "            if ortho not in universal_ortho_coords.keys():\n",
    "                universal_ortho_coords[ortho] = set()\n",
    "            universal_ortho_coords[ortho].add(coord)\n",
    "        else:\n",
    "            print(\"warning, {} {} has only {}\".format(ortho, coord, sp_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from bokeh.charts import Histogram, show\n",
    "from bokeh.io import output_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for ortho in sorted(universal_ortho_coords.keys()):\n",
    "    for coord in sorted(universal_ortho_coords[ortho]):\n",
    "        start, end = coord\n",
    "        length = end - start\n",
    "        data.append((ortho, coord, length))\n",
    "\n",
    "df = pandas.DataFrame.from_records(data=data, columns=['ortho', 'coord', 'Aligned CDS Length'])\n",
    "print(df.describe())\n",
    "\n",
    "output_notebook()\n",
    "hist = Histogram(df, values=\"Aligned CDS Length\", title=\"Aligned CDS Length Histogram\")\n",
    "show(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fasta prep\n",
    "fasta_prep = {}\n",
    "for ortho in universal_ortho_coords:\n",
    "    fasta_prep[ortho] = []\n",
    "    for coord in universal_ortho_coords[ortho]:\n",
    "            temp_sp_list = []\n",
    "            for sp in sorted(aligned_fasta[ortho]):\n",
    "                start,end = coord\n",
    "                seq = aligned_fasta[ortho][sp].seq[start:end]\n",
    "                des = aligned_fasta[ortho][sp].description\n",
    "                seqReq = SeqRecord(seq, id=sp, description=des)\n",
    "                if sp in template_species_list:\n",
    "                    fasta_prep[ortho].append(seqReq)\n",
    "                else:\n",
    "                    temp_sp_list.append(seqReq)\n",
    "\n",
    "            fasta_prep[ortho].extend(temp_sp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp(fasta_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fasta_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ortho in fasta_prep:\n",
    "    fasta_prep[ortho] = [seqReq for seqReq in fasta_prep[ortho] if (gapPercent(seqReq.seq) <= max_gap_percent) and (longestGap(seqReq.seq) <= max_gap_length)]\n",
    "    \n",
    "fasta_prep = {ortho:seq_list for ortho,seq_list in fasta_prep.items() if len(seq_list) >= 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fasta_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fasta output\n",
    "for ortho in fasta_prep:\n",
    "    with open(output_path + ortho + \".13spp.fasta\", \"w\") as f:\n",
    "        for seqReq in fasta_prep[ortho]:\n",
    "            f.write(seqReq.format(\"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for ortho in sorted(fasta_prep.keys()):\n",
    "    sp_count = len(fasta_prep[ortho])\n",
    "    data.append((ortho, sp_count))\n",
    "\n",
    "df = pandas.DataFrame.from_records(data=data, columns=['ortho', 'sp_count'])\n",
    "print(df.describe())\n",
    "\n",
    "output_notebook()\n",
    "hist = Histogram(df, values=\"sp_count\", title=\"Species Count per Ortho Histogram\")\n",
    "show(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# analize coverage\n",
    "coverage = {}\n",
    "for ortho,rec_list in fasta_prep.items():\n",
    "    for seqRec in rec_list:\n",
    "        sp = seqRec.id\n",
    "        if sp not in coverage.keys():\n",
    "            coverage[sp] = set()\n",
    "        coverage[sp].add(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sp,count in sorted([(sp, len(coverage[sp])) for sp in coverage.keys()], key=lambda x: x[1]):\n",
    "    print(\"species: {}\\torthos: {}\".format(sp,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_species_list = sorted(coverage.keys())\n",
    "full_species_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "species_index = {}\n",
    "for i,sp in enumerate(full_species_list):\n",
    "    species_index[sp] = i\n",
    "species_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sp1,sp2,count in sorted([(sp1, sp2, len(set.intersection(coverage[sp1], coverage[sp2]))) for sp1 in full_species_list for sp2 in full_species_list[species_index[sp1]:] if sp1 != sp2], key=lambda x: x[2]):\n",
    "    print(\"sp1: {}\\tsp2: {}\\torthos: {}\".format(sp1,sp2,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.intersection(coverage['Aobl'], coverage['Bjar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for ortho in sorted(set.intersection(coverage['Aobl'], coverage['Bjar'])):\n",
    "    sp_count = len(fasta_prep[ortho])\n",
    "    data.append((ortho, sp_count))\n",
    "\n",
    "df = pandas.DataFrame.from_records(data=data, columns=['ortho', 'sp_count'])\n",
    "print(df.describe())\n",
    "\n",
    "output_notebook()\n",
    "hist = Histogram(df, values=\"sp_count\", title=\"Histogram of Species Count per Ortho shaired by Aobl and Bjar\")\n",
    "show(hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
