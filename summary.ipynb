{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gffutils\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "import json\n",
    "from pyfaidx import Fasta\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_species_list = ['Bjar', 'Aobl', 'Bmin', 'Asus', 'Btry', 'Afra', 'Blat', 'Bzon', 'Bcor', 'Ccap', 'Bcur', 'Bole', 'Bdor']\n",
    "species_list = [\"Bcur\", \"Bdor\", \"Bole\", \"Ccap\"]\n",
    "transvestigated_species_set = {'Bcor', 'Blat', 'Bzon', 'Afra', 'Bmin', 'Bjar', 'Aobl'}\n",
    "gff_path = \"./input/gff/\"\n",
    "fasta_path = \"./input/fasta/\"\n",
    "groups_fn = \"./input/groups_filtered_6181genes.txt\"\n",
    "output_path = \"./output/\"\n",
    "input_path = \"./input/\"\n",
    "intermediate_path = \"./intermediate/\"\n",
    "aligned_fasta_path = \"./intermediate/13spp_aligned_trimmed_filtered_fasta/\"\n",
    "p3_out_path = \"./input/P3/\"\n",
    "primer_products_path = \"./intermediate/primer_products/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create handles for all .fasta files in fasta directory\n",
    "fasta_fn = {name.split('.13spp.fasta')[0]: primer_products_path + name for name in os.listdir(primer_products_path) if\n",
    "         ((\".13spp.fasta\" in name) and (\".13spp.fasta.fai\" not in name))}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# read and parse fasta files for each species\n",
    "fasta = {}\n",
    "for ortho in fasta_fn.keys():\n",
    "    fasta[ortho] = {seq_record.id : seq_record \n",
    "                                      for seq_record in SeqIO.parse(fasta_fn[ortho],\n",
    "                                                                    \"fasta\", alphabet=IUPAC.ambiguous_dna)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "primer = {}\n",
    "for p3_out_fn in os.listdir(p3_out_path):\n",
    "    ortho = p3_out_fn.split('.degenerate.p3.out')[0]\n",
    "    with open(p3_out_path + p3_out_fn, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip().split('=') for line in lines]\n",
    "        lines = {key:value for key,value in lines if key is not ''}\n",
    "        if lines['PRIMER_PAIR_NUM_RETURNED'] is not '0':\n",
    "            left,l_len = lines['PRIMER_LEFT_0'].split(',')\n",
    "            right,r_len = lines['PRIMER_RIGHT_0'].split(',')\n",
    "            primer[ortho] = (str(int(lines['PRIMER_PAIR_0_PRODUCT_SIZE']) - int(l_len) - int(r_len)),\n",
    "                             lines['PRIMER_LEFT_0_SEQUENCE'],\n",
    "                             lines['PRIMER_RIGHT_0_SEQUENCE'],\n",
    "                             lines['PRIMER_LEFT_0_TM'],\n",
    "                             lines['PRIMER_RIGHT_0_TM'])\n",
    "len(primer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"input/net_PI_avg_edited.txt\", 'r') as f:\n",
    "    name_score = [line.strip().split() for line in f.readlines()[1:]]\n",
    "name_score = {line[0].split(\".13spp.fasta\")[0] : line[1] for line in name_score}\n",
    "name_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pre_padding_species.json\n",
    "with open(intermediate_path + \"pre_padding_species.json\", 'r') as f:\n",
    "    pre_padd_sp = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import ortholog groups\n",
    "with open(intermediate_path + \"groups.json\", 'r') as f:\n",
    "    parent_groups = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create handles for all .db files in intermediate directory\n",
    "gff_fn = {name.split('.gff.db')[0]: intermediate_path + name for name in os.listdir(intermediate_path) if \".gff.db\" in name}\n",
    "gff = {key: gffutils.FeatureDB(value) for key, value in gff_fn.items()}\n",
    "#gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for ortho in primer:\n",
    "    for sp in pre_padd_sp[ortho]:\n",
    "        if 'product' in gff[sp][parent_groups[ortho.split(\"_\")[0]][sp]].attributes.keys():\n",
    "            product = gff[sp][parent_groups[ortho.split(\"_\")[0]][sp]]['product'][0]\n",
    "        else:\n",
    "            product = \"N/A\"\n",
    "        score = name_score[ortho]\n",
    "        data.append((ortho, score, sp, product, *primer[ortho]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_order = { 'Bcur':1,\n",
    "             'Bdor':2,\n",
    "             'Bole':3,\n",
    "             'Ccap':4,\n",
    "             'Bcor':5,\n",
    "             'Blat':6,\n",
    "             'Bzon':7,\n",
    "             'Afra':8,\n",
    "             'Bmin':9,\n",
    "             'Bjar':10,\n",
    "             'Aobl':11,\n",
    "             'Asus':12,\n",
    "             'Btry':13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sorted(data, key=lambda x: (x[0], sp_order[x[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = ['Exon_Name',\n",
    " 'PI_Score',\n",
    " 'Species',\n",
    " 'Gene_Product',\n",
    " 'Target_Sequence_Length',\n",
    " 'PRIMER_LEFT_0_SEQUENCE',\n",
    " 'PRIMER_RIGHT_0_SEQUENCE',\n",
    " 'PRIMER_LEFT_0_TM',\n",
    " 'PRIMER_RIGHT_0_TM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"./output/13spp_exon_primer_data.csv\", \"w\") as f:\n",
    "    f.write(\",\".join(header))\n",
    "    for record in data:\n",
    "        f.write(\"\\n\" + \",\".join(record))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
