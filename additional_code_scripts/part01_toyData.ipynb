{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import gffutils\n",
    "from Bio import SeqIO\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pyfaidx import Fasta\n",
    "\n",
    "\n",
    "json_path = \"../data/part01/intermediate/json/\"\n",
    "db_path = \"../data/part01/intermediate/gff_databases/\"\n",
    "fasta_path = \"../data/part01/input/fasta/\"\n",
    "toy_data_dir = \"toy_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ortholog groups\n",
    "with open(json_path + \"groups.json\", 'r') as f:\n",
    "    parent_groups = json.load(f)\n",
    "    \n",
    "# create handles for all .db files in intermediate directory\n",
    "gff_fn = {name.split('.gff.db')[0]: db_path + name for name in os.listdir(db_path) if\n",
    "          \".gff.db\" in name}\n",
    "gff = {key: gffutils.FeatureDB(value) for key, value in gff_fn.items()}\n",
    "\n",
    "# create handles for all .fasta files in fasta directory\n",
    "fasta_fn = {name.split('.nt.fasta')[0]: fasta_path + name for name in os.listdir(fasta_path) if\n",
    "            ((\".nt.fasta\" in name) and (\".nt.fasta.fai\" not in name))}\n",
    "fasta = {}\n",
    "for sp,fn in fasta_fn.items():\n",
    "    fasta[sp] = {seq_record.id: seq_record\n",
    "                            for seq_record in SeqIO.parse(fn, \"fasta\", alphabet=IUPAC.ambiguous_dna)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good = [\"orth10018\",\n",
    "        \"orth10019\",\n",
    "        \"orth10023\",\n",
    "        \"orth10028\",\n",
    "        \"orth10034\",\n",
    "        \"orth10035\"]\n",
    "\n",
    "\n",
    "rejected_on_second_alignment = [\"orth4341\",\n",
    "                              \"orth4271\",\n",
    "                              \"orth2902\"]\n",
    "\n",
    "rejected_on_first_alignment = ['orth10015',\n",
    "                               'orth10018',\n",
    "                               'orth10019',\n",
    "                               'orth10020',\n",
    "                               'orth10022',\n",
    "                               'orth10023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toys = set(good + rejected_on_second_alignment + rejected_on_first_alignment)\n",
    "toy_groups = {key:parent_groups[key] for key in toys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_seqid = {}\n",
    "for ortho in toy_groups:\n",
    "    for sp in toy_groups[ortho]:\n",
    "        if sp not in sp_seqid:\n",
    "            sp_seqid[sp] = set()\n",
    "        sp_seqid[sp].add(toy_groups[ortho][sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(toy_data_dir, ignore_errors=True)\n",
    "for d in [\"gff\", \"fasta\"]:\n",
    "    os.makedirs(toy_data_dir + d, exist_ok=True)\n",
    "for sp in sp_seqid:\n",
    "    with open(toy_data_dir + \"gff/\" + sp + \".gff\", \"w\") as f:\n",
    "        for parent in sp_seqid[sp]:\n",
    "            m = gff[sp][parent]\n",
    "            f.write(str(m) + \"\\n\")\n",
    "            for c in gff[sp].children(m):\n",
    "                f.write(str(c) + \"\\n\")\n",
    "    with open(toy_data_dir + \"fasta/\" + sp + \".fasta\", \"w\") as f:\n",
    "        scafs = set()\n",
    "        for parent in sp_seqid[sp]:\n",
    "            m = gff[sp][parent]\n",
    "            scafs.add(m.chrom)\n",
    "        for scaf in scafs:\n",
    "            f.write(fasta[sp][scaf].format(\"fasta\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
